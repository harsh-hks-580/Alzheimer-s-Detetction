{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "toc-autonumbering": false,
    "toc-showcode": false,
    "toc-showmarkdowntxt": false,
    "toc-showtags": false,
    "colab": {
      "name": "b1370a31a0de55f67dc4747c3d29d9d7",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harsh-hks-580/Alzheimer-s-Detetction/blob/main/b1370a31a0de55f67dc4747c3d29d9d7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W62ADQwg3Zp4"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "<p style=\"text-align: center\"><img src=\"https://gitlab.aicrowd.com/aicrowd/assets/-/raw/master/challenges/clock-decomposition/notebook-banner.jpg?inline=false\" alt=\"Drawing\" style=\"height: 400px;\"/></p>"
      ],
      "id": "W62ADQwg3Zp4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": "true",
        "tags": [],
        "id": "rOznDgVE3Zp6"
      },
      "source": [
        "# What is the notebook about?\n",
        "\n",
        "The challenge is to use the features extracted from the Clock Drawing Test to build an automated and algorithm to predict whether each participant is one of three phases:\n",
        "\n",
        "1)    Pre-Alzheimer‚Äôs (Early Warning)\n",
        "2)    Post-Alzheimer‚Äôs (Detection)\n",
        "3)    Normal (Not an Alzheimer‚Äôs patient)\n",
        "\n",
        "In machine learning terms: this is a 3-class classification task.\n",
        "\n",
        "# How to use this notebook? üìù\n",
        "\n",
        "<p style=\"text-align: center\"><img src=\"https://gitlab.aicrowd.com/aicrowd/assets/-/raw/master/notebook/aicrowd_notebook_submission_flow.png?inline=false\" alt=\"notebook overview\" style=\"width: 650px;\"/></p>\n",
        "\n",
        "- **Update the config parameters**. You can define the common variables here\n",
        "\n",
        "Variable | Description\n",
        "--- | ---\n",
        "`AICROWD_DATASET_PATH` | Path to the file containing test data (The data will be available at `/ds_shared_drive/` on aridhia workspace). This should be an absolute path.\n",
        "`AICROWD_PREDICTIONS_PATH` | Path to write the output to.\n",
        "`AICROWD_ASSETS_DIR` | In case your notebook needs additional files (like model weights, etc.,), you can add them to a directory and specify the path to the directory here (please specify relative path). The contents of this directory will be sent to AIcrowd for evaluation.\n",
        "`AICROWD_API_KEY` | In order to submit your code to AIcrowd, you need to provide your account's API key. This key is available at https://www.aicrowd.com/participants/me\n",
        "\n",
        "- **Installing packages**. Please use the [Install packages üóÉ](#install-packages-) section to install the packages\n",
        "- **Training your models**. All the code within the [Training phase ‚öôÔ∏è](#training-phase-) section will be skipped during evaluation. **Please make sure to save your model weights in the assets directory and load them in the predictions phase section** "
      ],
      "id": "rOznDgVE3Zp6"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "__riTMue3Zp6"
      },
      "source": [
        "# Setup AIcrowd Utilities üõ†\n",
        "\n",
        "We use this to bundle the files for submission and create a submission on AIcrowd. Do not edit this block."
      ],
      "id": "__riTMue3Zp6"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qwyoGxs3Zp7"
      },
      "source": [
        "!pip install -q -U aicrowd-cli"
      ],
      "id": "0qwyoGxs3Zp7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ajGYap23Zp7"
      },
      "source": [
        "%load_ext aicrowd.magic"
      ],
      "id": "9ajGYap23Zp7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "uZ6HcBlX3Zp8"
      },
      "source": [
        "# AIcrowd Runtime Configuration üß∑\n",
        "\n",
        "Define configuration parameters. Please include any files needed for the notebook to run under `ASSETS_DIR`. We will copy the contents of this directory to your final submission file üôÇ\n",
        "\n",
        "The dataset is available under `/ds_shared_drive` on the workspace."
      ],
      "id": "uZ6HcBlX3Zp8"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9o_EH9V33Zp8"
      },
      "source": [
        "import os\n",
        "\n",
        "# Please use the absolute for the location of the dataset.\n",
        "# Or you can use relative path with `os.getcwd() + \"test_data/validation.csv\"`\n",
        "AICROWD_DATASET_PATH = os.getenv(\"DATASET_PATH\", \"/ds_shared_drive/validation.csv\")\n",
        "AICROWD_PREDICTIONS_PATH = os.getenv(\"PREDICTIONS_PATH\", \"predictions.csv\")\n",
        "AICROWD_ASSETS_DIR = \"assets\""
      ],
      "id": "9o_EH9V33Zp8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "cA4-uuFu3Zp8"
      },
      "source": [
        "# Install packages üóÉ\n",
        "\n",
        "Please add all pacakage installations in this section"
      ],
      "id": "cA4-uuFu3Zp8"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anC93kw_3Zp9",
        "outputId": "55d1feb9-ddb5-4d21-e9e9-bd26293c1a78"
      },
      "source": [
        "!pip install scikit-learn\n",
        "!pip install catboost"
      ],
      "id": "anC93kw_3Zp9",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.8/site-packages (0.23.2)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /opt/anaconda3/lib/python3.8/site-packages (from scikit-learn) (1.19.2)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /opt/anaconda3/lib/python3.8/site-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/lib/python3.8/site-packages (from scikit-learn) (2.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /opt/anaconda3/lib/python3.8/site-packages (from scikit-learn) (0.17.0)\n",
            "Requirement already satisfied: catboost in /opt/anaconda3/lib/python3.8/site-packages (0.26)\n",
            "Requirement already satisfied: matplotlib in /opt/anaconda3/lib/python3.8/site-packages (from catboost) (3.3.2)\n",
            "Requirement already satisfied: graphviz in /opt/anaconda3/lib/python3.8/site-packages (from catboost) (0.16)\n",
            "Requirement already satisfied: plotly in /opt/anaconda3/lib/python3.8/site-packages (from catboost) (4.14.3)\n",
            "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.8/site-packages (from catboost) (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /opt/anaconda3/lib/python3.8/site-packages (from catboost) (1.19.2)\n",
            "Requirement already satisfied: six in /opt/anaconda3/lib/python3.8/site-packages (from catboost) (1.15.0)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /opt/anaconda3/lib/python3.8/site-packages (from catboost) (1.1.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/anaconda3/lib/python3.8/site-packages (from matplotlib->catboost) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.8/site-packages (from matplotlib->catboost) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /opt/anaconda3/lib/python3.8/site-packages (from matplotlib->catboost) (2.8.1)\n",
            "Requirement already satisfied: certifi>=2020.06.20 in /opt/anaconda3/lib/python3.8/site-packages (from matplotlib->catboost) (2020.6.20)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /opt/anaconda3/lib/python3.8/site-packages (from matplotlib->catboost) (2.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /opt/anaconda3/lib/python3.8/site-packages (from matplotlib->catboost) (8.0.1)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /opt/anaconda3/lib/python3.8/site-packages (from plotly->catboost) (1.3.3)\n",
            "Requirement already satisfied: pytz>=2017.2 in /opt/anaconda3/lib/python3.8/site-packages (from pandas>=0.24.0->catboost) (2020.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "v_fMC5en3Zp-"
      },
      "source": [
        "# Define preprocessing code üíª\n",
        "\n",
        "The code that is common between the training and the prediction sections should be defined here. During evaluation, we completely skip the training section. Please make sure to add any common logic between the training and prediction sections here."
      ],
      "id": "v_fMC5en3Zp-"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQi2w6tc3Zp-"
      },
      "source": [
        "### Import common packages\n",
        "\n",
        "Please import packages that are common for training and prediction phases here."
      ],
      "id": "DQi2w6tc3Zp-"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xSV-tqB3Zp_"
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt # data visualization\n",
        "from sklearn.metrics import f1_score, log_loss, balanced_accuracy_score, roc_auc_score, make_scorer, confusion_matrix, plot_confusion_matrix\n",
        "import pickle\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn import preprocessing\n",
        "import catboost\n",
        "from catboost import CatBoostClassifier, Pool\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.utils import class_weight\n",
        "%matplotlib inline\n",
        "# pd.set_option('display.max_rows', None)"
      ],
      "id": "-xSV-tqB3Zp_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "Q8H6vKDK3Zp_"
      },
      "source": [
        "# Training phase ‚öôÔ∏è\n",
        "\n",
        "You can define your training code here. This sections will be skipped during evaluation."
      ],
      "id": "Q8H6vKDK3Zp_"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDmK2T4J3Zp_"
      },
      "source": [
        "## Load training data"
      ],
      "id": "DDmK2T4J3Zp_"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDytbm8h3ZqA"
      },
      "source": [
        "df2 = pd.read_csv(os.getenv(\"DATASET_PATH\", \"/ds_shared_drive/train.csv\"))\n",
        "x_test = pd.read_csv(os.getenv(\"DATASET_PATH\", \"/ds_shared_drive/validation.csv\"))\n",
        "y_test = pd.read_csv(os.getenv(\"DATASET_PATH\", \"/ds_shared_drive/validation_ground_truth.csv\"))\n",
        "test = pd.merge(x_test,y_test,on='row_id')\n",
        "df = df2.append(test)\n",
        "df.drop(columns=['row_id'],inplace=True)\n",
        "col_names = df.columns"
      ],
      "id": "gDytbm8h3ZqA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bx3m8G0z3ZqA",
        "outputId": "39079e9c-7a9b-4b99-9baa-d1107a510d02"
      },
      "source": [
        "# col_drop = ['actual_hour_digit','actual_minute_digit','single_hand_length' ,'between_digits_angle_ccw_sum']\n",
        "# col_names =list(set(df.columns)-set(col_drop))\n",
        "cat_var = ['missing_digit_1', 'missing_digit_2', 'missing_digit_3', 'missing_digit_4', 'missing_digit_5',\n",
        "           'missing_digit_6', 'missing_digit_7', 'missing_digit_8', 'missing_digit_9', 'missing_digit_10',\n",
        "           'missing_digit_11', 'missing_digit_12', 'sequence_flag_cw', 'sequence_flag_ccw', 'hand_count_dummy',\n",
        "           'intersection_pos_rel_centre', 'hour_pointing_digit', 'minute_pointing_digit', 'eleven_ten_error',\n",
        "           'other_error', 'pred_tremor', 'centre_dot_detect']\n",
        "cont_var = list(set(col_names)-set(cat_var)-set(['diagnosis']))\n",
        "print(len(cat_var),len(cont_var))"
      ],
      "id": "bx3m8G0z3ZqA",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "22 98\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0MwsW0o3ZqB"
      },
      "source": [
        "# df.drop(col_drop,axis=1,inplace=True)\n",
        "for col in cat_var:\n",
        "    df[col].fillna(1000,inplace=True)\n",
        "# def_val = {}\n",
        "# for col in cont_var :\n",
        "#     def_val[col] = df[col].mean()\n",
        "#     df[col].fillna(def_val[col],inplace=True)"
      ],
      "id": "I0MwsW0o3ZqB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1CaEcna3ZqB"
      },
      "source": [
        "a_file = open(AICROWD_ASSETS_DIR+\"/cat_var.pkl\", \"wb\")\n",
        "pickle.dump(cat_var, a_file)\n",
        "a_file.close()\n",
        "a_file = open(AICROWD_ASSETS_DIR+\"/cont_var.pkl\", \"wb\")\n",
        "pickle.dump(cont_var, a_file)\n",
        "a_file.close()\n",
        "# a_file = open(AICROWD_ASSETS_DIR+\"/def_val.pkl\", \"wb\")\n",
        "# pickle.dump(def_val, a_file)\n",
        "# a_file.close()"
      ],
      "id": "s1CaEcna3ZqB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYEC4AW33ZqB"
      },
      "source": [
        "# df.drop(col_drop,axis=1,inplace=True)\n",
        "df[[feature for feature in cat_var if feature != 'intersection_pos_rel_centre']] = df[[feature for feature in cat_var if feature != 'intersection_pos_rel_centre']].astype(int)\n",
        "x_train, x_test, y_train, y_test = train_test_split(df.drop(['diagnosis'], axis=1), df['diagnosis'], \n",
        "                                                    test_size=0.01, stratify=df['diagnosis'], random_state=42)\n",
        "# x_train = df.drop(['diagnosis'],axis=1).copy()\n",
        "# y_train = df['diagnosis']"
      ],
      "id": "kYEC4AW33ZqB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5mVLjFQ3ZqC",
        "outputId": "fefcb5f6-4289-4bbe-9ccd-3d8fec71652f"
      },
      "source": [
        "x_train.shape"
      ],
      "id": "w5mVLjFQ3ZqC",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32807, 120)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Q_zUcdi3ZqC"
      },
      "source": [
        "# ct = ColumnTransformer([\n",
        "#         ('ColumnTransform', StandardScaler(), cont_var)\n",
        "#     ], remainder='passthrough')\n",
        "\n",
        "# x_train = ct.fit_transform(x_train)\n",
        "# x_test = ct.transform(x_test)"
      ],
      "id": "7Q_zUcdi3ZqC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0umFtI7_3ZqC",
        "outputId": "b499198f-6b5d-489c-c6ef-8bb1fb622a76"
      },
      "source": [
        "y_train.head()"
      ],
      "id": "0umFtI7_3ZqC",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26094    normal\n",
              "15378    normal\n",
              "26099    normal\n",
              "3149     normal\n",
              "15206    normal\n",
              "Name: diagnosis, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5hPlguW3ZqD"
      },
      "source": [
        "## Train your model"
      ],
      "id": "D5hPlguW3ZqD"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaqBAdgG3ZqF",
        "outputId": "ed41e284-e067-47bd-e32b-ad6e9a2f498a"
      },
      "source": [
        "my_model = CatBoostClassifier(iterations=300,learning_rate=0.05,max_depth = 7,\n",
        "                              loss_function='MultiClassOneVsAll',auto_class_weights='SqrtBalanced',\n",
        "                             early_stopping_rounds=10)\n",
        "my_model.fit(x_train, y_train,eval_set=(x_test,y_test),\n",
        "             cat_features=cat_var, verbose=100)"
      ],
      "id": "vaqBAdgG3ZqF",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0:\tlearn: 0.6656025\ttest: 0.6658973\tbest: 0.6658973 (0)\ttotal: 299ms\tremaining: 1m 29s\n",
            "100:\tlearn: 0.2936796\ttest: 0.3086743\tbest: 0.3084828 (96)\ttotal: 27.5s\tremaining: 54.2s\n",
            "Stopped by overfitting detector  (10 iterations wait)\n",
            "\n",
            "bestTest = 0.3051860565\n",
            "bestIteration = 129\n",
            "\n",
            "Shrink model to first 130 iterations.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<catboost.core.CatBoostClassifier at 0x7f1f5075a640>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFhcNgmy3ZqG",
        "outputId": "8a916b12-9a03-4af4-9c42-941a82a4d25b"
      },
      "source": [
        "preds =  my_model.predict_proba(x_test)\n",
        "for i,x in enumerate(preds):\n",
        "    preds[i] = preds[i]/(preds[i][0]+preds[i][1]+preds[i][2])\n",
        "print(f1_score(y_test, my_model.predict(x_test),average='macro'),log_loss(y_test,preds))"
      ],
      "id": "aFhcNgmy3ZqG",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.4506883090199301 0.26749970379068166\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUkJPy3b3ZqG"
      },
      "source": [
        "## Save your trained model"
      ],
      "id": "LUkJPy3b3ZqG"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HznSdYo53ZqG"
      },
      "source": [
        "filename = AICROWD_ASSETS_DIR+\"/finalized_model.sav\"\n",
        "pickle.dump(my_model, open(filename, 'wb'))"
      ],
      "id": "HznSdYo53ZqG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "ZfGynp2j3ZqG"
      },
      "source": [
        "# Prediction phase üîé\n",
        "\n",
        "Please make sure to save the weights from the training section in your assets directory and load them in this section"
      ],
      "id": "ZfGynp2j3ZqG"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOxABtDy3ZqH"
      },
      "source": [
        "filename = AICROWD_ASSETS_DIR+\"/finalized_model.sav\"\n",
        "model = pickle.load(open(filename, 'rb'))\n",
        "a_file = open(AICROWD_ASSETS_DIR+\"/cat_var.pkl\", \"rb\")\n",
        "cat_var = pickle.load(a_file)\n",
        "a_file.close()\n",
        "a_file = open(AICROWD_ASSETS_DIR+\"/cont_var.pkl\", \"rb\")\n",
        "cont_var = pickle.load(a_file)\n",
        "# a_file.close()\n",
        "# a_file = open(AICROWD_ASSETS_DIR+\"/col_drop.pkl\", \"rb\")\n",
        "# col_drop = pickle.load(a_file)\n",
        "# a_file.close()"
      ],
      "id": "HOxABtDy3ZqH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGjWU-zx3ZqH"
      },
      "source": [
        "## Load test data"
      ],
      "id": "UGjWU-zx3ZqH"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEjtdM_d3ZqH"
      },
      "source": [
        "test_data = pd.read_csv(AICROWD_DATASET_PATH)\n",
        "# test_data.drop(col_drop,axis=1,inplace=True)"
      ],
      "id": "oEjtdM_d3ZqH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqDYk43v3ZqH"
      },
      "source": [
        "test_data[cat_var] = test_data[cat_var].fillna(1000)\n",
        "test_data[[feature for feature in cat_var if feature != 'intersection_pos_rel_centre']] = test_data[[feature for feature in cat_var if feature != 'intersection_pos_rel_centre']].astype(int)"
      ],
      "id": "aqDYk43v3ZqH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TO-zIuKw3ZqH"
      },
      "source": [
        "preds = model.predict_proba(test_data.drop(['row_id'], axis=1))"
      ],
      "id": "TO-zIuKw3ZqH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFTf8a9S3ZqI"
      },
      "source": [
        "## Generate predictions"
      ],
      "id": "tFTf8a9S3ZqI"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsTueS-j3ZqI"
      },
      "source": [
        "predictions = {\n",
        "    \"row_id\":test_data[\"row_id\"].values,\n",
        "    \"normal_diagnosis_probability\": preds[:, 0],\n",
        "    \"post_alzheimer_diagnosis_probability\": preds[:, 1],\n",
        "    \"pre_alzheimer_diagnosis_probability\": preds[:, 2],\n",
        "}\n",
        "\n",
        "predictions_df = pd.DataFrame.from_dict(predictions)"
      ],
      "id": "lsTueS-j3ZqI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wfUDgnB3ZqI",
        "outputId": "79b1b9e0-bac6-4805-b063-e13a3501afb0"
      },
      "source": [
        "pred_sum = predictions_df['normal_diagnosis_probability'] + predictions_df['post_alzheimer_diagnosis_probability'] + predictions_df['pre_alzheimer_diagnosis_probability']\n",
        "predictions_df['normal_diagnosis_probability'] /= pred_sum \n",
        "predictions_df['post_alzheimer_diagnosis_probability'] /= pred_sum \n",
        "predictions_df['pre_alzheimer_diagnosis_probability'] /= pred_sum\n",
        "predictions_df['normal_diagnosis_probability'] + predictions_df['post_alzheimer_diagnosis_probability'] + predictions_df['pre_alzheimer_diagnosis_probability']"
      ],
      "id": "0wfUDgnB3ZqI",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      1.0\n",
              "1      1.0\n",
              "2      1.0\n",
              "3      1.0\n",
              "4      1.0\n",
              "      ... \n",
              "357    1.0\n",
              "358    1.0\n",
              "359    1.0\n",
              "360    1.0\n",
              "361    1.0\n",
              "Length: 362, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mufchxt3ZqI",
        "outputId": "02193f43-3986-4cad-a962-170e6e9971f4"
      },
      "source": [
        "predictions_df.head()"
      ],
      "id": "2mufchxt3ZqI",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>row_id</th>\n",
              "      <th>normal_diagnosis_probability</th>\n",
              "      <th>post_alzheimer_diagnosis_probability</th>\n",
              "      <th>pre_alzheimer_diagnosis_probability</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LA9JQ1JZMJ9D2MBZV</td>\n",
              "      <td>0.604323</td>\n",
              "      <td>0.263683</td>\n",
              "      <td>0.131994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>PSSRCWAPTAG72A1NT</td>\n",
              "      <td>0.588046</td>\n",
              "      <td>0.220323</td>\n",
              "      <td>0.191631</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>GCTODIZJB42VCBZRZ</td>\n",
              "      <td>0.955143</td>\n",
              "      <td>0.024025</td>\n",
              "      <td>0.020832</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7YMVQGV1CDB1WZFNE</td>\n",
              "      <td>0.317031</td>\n",
              "      <td>0.581333</td>\n",
              "      <td>0.101636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>PHEQC6DV3LTFJYIJU</td>\n",
              "      <td>0.582830</td>\n",
              "      <td>0.334544</td>\n",
              "      <td>0.082626</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              row_id  normal_diagnosis_probability  \\\n",
              "0  LA9JQ1JZMJ9D2MBZV                      0.604323   \n",
              "1  PSSRCWAPTAG72A1NT                      0.588046   \n",
              "2  GCTODIZJB42VCBZRZ                      0.955143   \n",
              "3  7YMVQGV1CDB1WZFNE                      0.317031   \n",
              "4  PHEQC6DV3LTFJYIJU                      0.582830   \n",
              "\n",
              "   post_alzheimer_diagnosis_probability  pre_alzheimer_diagnosis_probability  \n",
              "0                              0.263683                             0.131994  \n",
              "1                              0.220323                             0.191631  \n",
              "2                              0.024025                             0.020832  \n",
              "3                              0.581333                             0.101636  \n",
              "4                              0.334544                             0.082626  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TETGEIVV3ZqJ"
      },
      "source": [
        "## Save predictions üì®"
      ],
      "id": "TETGEIVV3ZqJ"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tflk8-73ZqJ"
      },
      "source": [
        "predictions_df.to_csv(AICROWD_PREDICTIONS_PATH, index=False)"
      ],
      "id": "_tflk8-73ZqJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "xM3gk8mJ3ZqJ"
      },
      "source": [
        "# Submit to AIcrowd üöÄ\n",
        "\n",
        "**NOTE: PLEASE SAVE THE NOTEBOOK BEFORE SUBMITTING IT (Ctrl + S)**"
      ],
      "id": "xM3gk8mJ3ZqJ"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXWhN4kQ3ZqK",
        "outputId": "23419f74-5822-4632-f28a-0ddd3700ed16"
      },
      "source": [
        "!DATASET_PATH=$AICROWD_DATASET_PATH \\\n",
        "aicrowd notebook submit \\\n",
        "    --assets-dir $AICROWD_ASSETS_DIR \\\n",
        "    --challenge addi-alzheimers-detection-challenge"
      ],
      "id": "pXWhN4kQ3ZqK",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Got more than 1 jupyter server, selecting the latest session\n",
            "WARNING: Got more than 1 jupyter server, selecting the latest session\n",
            "Using notebook: /home/desktop2/Desktop/workspace/harsh_submit.ipynb for submission...\n",
            "Removing existing files from submission directory...\n",
            "WARNING: Got more than 1 jupyter server, selecting the latest session\n",
            "WARNING: Got more than 1 jupyter server, selecting the latest session\n",
            "Scrubbing API keys from the notebook...\n",
            "Collecting notebook...\n",
            "WARNING: Got more than 1 jupyter server, selecting the latest session\n",
            "Validating the submission...\n",
            "Executing install.ipynb...\n",
            "[NbConvertApp] Converting notebook /home/desktop2/Desktop/workspace/submission/install.ipynb to notebook\n",
            "[NbConvertApp] Executing notebook with kernel: python\n",
            "[NbConvertApp] Writing 4066 bytes to /home/desktop2/Desktop/workspace/submission/install.nbconvert.ipynb\n",
            "Executing predict.ipynb...\n",
            "[NbConvertApp] Converting notebook /home/desktop2/Desktop/workspace/submission/predict.ipynb to notebook\n",
            "[NbConvertApp] Executing notebook with kernel: python\n",
            "[NbConvertApp] Writing 16221 bytes to /home/desktop2/Desktop/workspace/submission/predict.nbconvert.ipynb\n",
            "\u001b[2K\u001b[1;34msubmission.zip\u001b[0m \u001b[38;2;114;156;31m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[35m100.0%\u001b[0m ‚Ä¢ \u001b[32m5.9/5.8 MB\u001b[0m ‚Ä¢ \u001b[31m2.5 MB/s\u001b[0m ‚Ä¢ \u001b[36m0:00:00\u001b[0m[0m ‚Ä¢ \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
            "\u001b[?25h                                                 ‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ                                                 \n",
            "                                                 ‚îÇ \u001b[1mSuccessfully submitted!\u001b[0m ‚îÇ                                                 \n",
            "                                                 ‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ                                                 \n",
            "\u001b[3m                                                       Important links                                                       \u001b[0m\n",
            "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
            "‚îÇ  This submission ‚îÇ https://www.aicrowd.com/challenges/addi-alzheimers-detection-challenge/submissions/145212              ‚îÇ\n",
            "‚îÇ                  ‚îÇ                                                                                                        ‚îÇ\n",
            "‚îÇ  All submissions ‚îÇ https://www.aicrowd.com/challenges/addi-alzheimers-detection-challenge/submissions?my_submissions=true ‚îÇ\n",
            "‚îÇ                  ‚îÇ                                                                                                        ‚îÇ\n",
            "‚îÇ      Leaderboard ‚îÇ https://www.aicrowd.com/challenges/addi-alzheimers-detection-challenge/leaderboards                    ‚îÇ\n",
            "‚îÇ                  ‚îÇ                                                                                                        ‚îÇ\n",
            "‚îÇ Discussion forum ‚îÇ https://discourse.aicrowd.com/c/addi-alzheimers-detection-challenge                                    ‚îÇ\n",
            "‚îÇ                  ‚îÇ                                                                                                        ‚îÇ\n",
            "‚îÇ   Challenge page ‚îÇ https://www.aicrowd.com/challenges/addi-alzheimers-detection-challenge                                 ‚îÇ\n",
            "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}